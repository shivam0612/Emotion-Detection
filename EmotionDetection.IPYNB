{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Variables and Setting path\n",
    "images=[]\n",
    "targets=[]\n",
    "\n",
    "# {angry : 0, happy : 1, sad : 2,neutral : 3, surprise : 4 } - 5 Diffetent EMOTIONS\n",
    "angry= r'D:\\Shivam\\Projects\\ML & AI\\Emotion Detection\\Dataset\\angry'\n",
    "happy=r'D:\\Shivam\\Projects\\ML & AI\\Emotion Detection\\Dataset\\happy'\n",
    "sad=r'D:\\Shivam\\Projects\\ML & AI\\Emotion Detection\\Dataset\\sad'\n",
    "neutral=r'D:\\Shivam\\Projects\\ML & AI\\Emotion Detection\\Dataset\\neutral'\n",
    "surprise=r'D:\\Shivam\\Projects\\ML & AI\\Emotion Detection\\Dataset\\surprise'\n",
    "fear=r'D:\\Shivam\\Projects\\ML & AI\\Emotion Detection\\Dataset\\fear'\n",
    "disgust=r'D:\\Shivam\\Projects\\ML & AI\\Emotion Detection\\Dataset\\disgust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting Image, Resizing, Converting It To Gray Scale, Storing in List Variables\n",
    "content=os.listdir(angry)\n",
    "\n",
    "for image in content:\n",
    "    try:\n",
    "        image_path=angry + '\\\\'+ image\n",
    "        image=cv2.imread(image_path)\n",
    "        image_grey=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        resized_image=cv2.resize(image_grey,(48,48))\n",
    "        images.append(resized_image)\n",
    "        targets.append(0)\n",
    "    except Exception as e:\n",
    "        print(\"exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting Image, Resizing, Converting It To Gray Scale, Storing in List Variables\n",
    "content=os.listdir(happy)\n",
    "\n",
    "for image in content:\n",
    "    try:\n",
    "        image_path=happy + '\\\\'+ image\n",
    "        image=cv2.imread(image_path)\n",
    "        image_grey=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        resized_image=cv2.resize(image_grey,(48,48))\n",
    "        images.append(resized_image)\n",
    "        targets.append(1)\n",
    "    except Exception as e:\n",
    "        print(\"exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Image, Resizing, Converting It To Gray Scale, Storing in List Variables\n",
    "content=os.listdir(sad)\n",
    "\n",
    "for image in content:\n",
    "    try:\n",
    "        image_path=sad + '\\\\'+ image\n",
    "        image=cv2.imread(image_path)\n",
    "        image_grey=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        resized_image=cv2.resize(image_grey,(48,48))\n",
    "        images.append(resized_image)\n",
    "        targets.append(2)\n",
    "    except Exception as e:\n",
    "        print(\"exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Image, Resizing, Converting It To Gray Scale, Storing in List Variables\n",
    "content=os.listdir(neutral)\n",
    "\n",
    "for image in content:\n",
    "    try:\n",
    "        image_path=neutral + '\\\\'+ image\n",
    "        image=cv2.imread(image_path)\n",
    "        image_grey=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        resized_image=cv2.resize(image_grey,(48,48))\n",
    "        images.append(resized_image)\n",
    "        targets.append(3)\n",
    "    except Exception as e:\n",
    "        print(\"exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Image, Resizing, Converting It To Gray Scale, Storing in List Variables\n",
    "content=os.listdir(surprise)\n",
    "\n",
    "for image in content:\n",
    "    try:\n",
    "        image_path=surprise + '\\\\'+ image\n",
    "        image=cv2.imread(image_path)\n",
    "        image_grey=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        resized_image=cv2.resize(image_grey,(48,48))\n",
    "        images.append(resized_image)\n",
    "        targets.append(4)\n",
    "    except Exception as e:\n",
    "        print(\"exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Image, Resizing, Converting It To Gray Scale, Storing in List Variables\n",
    "content=os.listdir(fear)\n",
    "\n",
    "for image in content:\n",
    "    try:\n",
    "        image_path=fear + '\\\\'+ image\n",
    "        image=cv2.imread(image_path)\n",
    "        image_grey=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        resized_image=cv2.resize(image_grey,(48,48))\n",
    "        images.append(resized_image)\n",
    "        targets.append(5)\n",
    "    except Exception as e:\n",
    "        print(\"exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Image, Resizing, Converting It To Gray Scale, Storing in List Variables\n",
    "content=os.listdir(disgust)\n",
    "\n",
    "for image in content:\n",
    "    try:\n",
    "        image_path=disgust + '\\\\'+ image\n",
    "        image=cv2.imread(image_path)\n",
    "        image_grey=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        resized_image=cv2.resize(image_grey,(48,48))\n",
    "        images.append(resized_image)\n",
    "        targets.append(6)\n",
    "    except Exception as se:\n",
    "        print(\"exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "images = np.array(images)/255.0\n",
    "targets = np.array(targets)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list variable for training \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, targets, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Array Dimensions\n",
    "X_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train=X_train.reshape(X_train.shape[0],48, 48, 1)\n",
    "X_test=X_test.reshape(X_test.shape[0],48,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding For Handling Categorical Values\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "Y_test=label_encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting To Binary Class Matrix\n",
    "Y_train=np_utils.to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Sequential model and Layers\n",
    "model= Sequential()\n",
    "\n",
    "model.add(Conv2D(200, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(150, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(100, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout((0.4)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "# Compiling Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model For Future Use\n",
    "cp = ModelCheckpoint('model-ED', verbose=0, save_best_only=True)\n",
    "# Training Model\n",
    "model.fit(X_train, Y_train, epochs = 50,  callbacks=[cp], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "model=load_model('model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Face Detection\n",
    "face_detect=cv2.CascadeClassifier(r'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing Video\n",
    "source = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    not_to_use, image = source.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detect.detectMultiScale(gray, 1.5,5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = gray[y:y+w, x:x+w]\n",
    "        resized_face = cv2.resize(face_roi, (100, 100))\n",
    "        normalized_Face = resized_face/255\n",
    "        reshaped_face = np.reshape(normalized_Face, (1, 100, 100, 1))\n",
    "        result = model.predict(reshaped_face)[0]\n",
    "        \n",
    "        # Using 5 Emotions as per definition        \n",
    "       \n",
    "        if np.amax(result)==result[0]:\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            cv2.putText(image,\"Angry\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(255,0,0),thickness=2)\n",
    "        if np.amax(result)==result[1]:\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "            cv2.putText(image,\"happy\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(255,0,255),thickness=2)\n",
    "        if np.amax(result)==result[2]:\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(image,\"neutral\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(0,255,0),thickness=2)\n",
    "        if np.amax(result)==result[3]:\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(255,255,50),2)\n",
    "            cv2.putText(image,\"sad\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(255,255,50),thickness=2)\n",
    "        if np.amax(result)==result[4]:\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(17,17,17),2)\n",
    "            cv2.putText(image,\"surprised\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(17,17,17),thickness=2)\n",
    "\n",
    "    Height=600\n",
    "    Width=600\n",
    "    dimension = (Width, Height)\n",
    "    resized_image = cv2.resize(image, dimension, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    cv2.imshow('Verzeo Final Project', resized_image)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}